{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import ConvMixer, MlpMixer\n",
    "from torchvision.datasets import CIFAR10, ImageFolder\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.empty_cache())\n",
    "print(torch.cuda.memory_summary(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "hdim=1024\n",
    "depth=32\n",
    "\n",
    "epochs=1\n",
    "\n",
    "scale=0.75\n",
    "reprob=0.25\n",
    "ra_m=8\n",
    "ra_n=1\n",
    "jitter=0.1\n",
    "psize=2\n",
    "conv_ks=5\n",
    "wd=0.01\n",
    "clip_norm=True\n",
    "lr_max=0.01\n",
    "workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if not Path('data/tiny-imagenet-200').exists():\n",
    "    os.system('wget http://cs231n.stanford.edu/tiny-imagenet-200.zip -P data')\n",
    "    os.system('unzip -qq data/tiny-imagenet-200.zip -d data')\n",
    "\n",
    "DATA_DIR = 'data/tiny-imagenet-200' # Original images come in shapes of [3,64,64]\n",
    "\n",
    "# Define training and validation data paths\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VALID_DIR = os.path.join(DATA_DIR, 'val')\n",
    "\n",
    "traindata = ImageFolder(TRAIN_DIR, transform=T.Compose([\n",
    "    T.RandomResizedCrop(64, scale=(scale, 1.0)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "]))\n",
    "\n",
    "valdata = ImageFolder(VALID_DIR, transform=T.Compose([\n",
    "    T.Resize(64),\n",
    "    T.CenterCrop(64),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "]))\n",
    "\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "valloader = DataLoader(valdata, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "print(len(traindata))\n",
    "print(len(valdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "# cifar10_std = (0.2471, 0.2435, 0.2616)\n",
    "# train_transform = T.Compose([\n",
    "#     T.RandomResizedCrop(32, scale=(scale, 1.0), ratio=(1.0, 1.0)),\n",
    "#     T.RandomHorizontalFlip(p=0.5),\n",
    "#     T.RandAugment(num_ops=ra_n, magnitude=ra_m),\n",
    "#     T.ColorJitter(jitter, jitter, jitter),\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(cifar10_mean, cifar10_std),\n",
    "#     T.RandomErasing(p=reprob)\n",
    "# ])\n",
    "\n",
    "# test_transform = T.Compose([\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(cifar10_mean, cifar10_std)\n",
    "# ])\n",
    "# traindata = CIFAR10(root=\"data\", train=True, download=True, transform=train_transform)\n",
    "# testdata = CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "# trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "# testloader = DataLoader(testdata, batch_size=batch_size, shuffle=False, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(model, get_time=True, record_time_len=100, verbose=False):\n",
    "    opt = optim.AdamW(model.parameters(), lr=lr_max, weight_decay=wd)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    preload_mem = 0.\n",
    "    load_mem = 0.\n",
    "    forward_mem = 0.\n",
    "    transfered = []\n",
    "    step_time = []\n",
    "    record_mem = 3\n",
    "    record_time = list(range(4, 4+record_time_len))\n",
    "    end_step = max(4+record_time_len, record_mem) if get_time else record_mem\n",
    "    if verbose:\n",
    "        print(f\"batch_size: {batch_size}, hdim: {hdim}, depth: {depth}\")\n",
    "        print(f\"Total params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        print(f\"Total params size in gb: {sum(p.element_size()*p.nelement() for p in model.parameters())/1024**3:.4f}GB\")\n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "        if i in record_time: start_step = time.time()\n",
    "        if i == record_mem: preload_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "        model.train()\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        if i == record_mem:\n",
    "            load_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "            transfered.append(X.element_size() * X.nelement())\n",
    "            transfered.append(y.element_size() * y.nelement())\n",
    "\n",
    "        # lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
    "        # opt.param_groups[0].update(lr=lr)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        if i == record_mem:\n",
    "            forward_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "            transfered.append(loss.element_size() * loss.nelement())\n",
    "\n",
    "        loss.backward()\n",
    "        if clip_norm:\n",
    "            # scaler.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # scaler.step(opt)\n",
    "        # scaler.update()\n",
    "        opt.step()\n",
    "        # print(f\"step {i} of {len(trainloader)}\")\n",
    "        if i in record_time: step_time.append(time.time() - start_step)\n",
    "        if verbose:\n",
    "            if i == record_time[-1]: print(f'avg step time: {np.mean(step_time):.4f} +- {np.std(step_time)}s')\n",
    "            if i == record_mem:\n",
    "                print(f'preload_mem: {preload_mem:.4f}GB, load_mem: {load_mem:.4f}GB, forward_mem: {forward_mem:.4f}GB, transfered: {np.array(transfered).mean()/1024:.4f}kB')\n",
    "        if i == end_step: break\n",
    "    return preload_mem, load_mem, forward_mem, transfered, step_time\n",
    "\n",
    "_ = get_stats(MlpMixer(num_blocks=depth, embed_dim=hdim).cuda(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(mem_limit, hdim=1024):\n",
    "    # binary search to find depth to fit in mem_limit\n",
    "    depth = 1\n",
    "    while True:\n",
    "        model = MlpMixer(num_blocks=depth, embed_dim=hdim).cuda() \n",
    "        _, _, forward_mem, _, _ = get_stats(model, get_time=False)\n",
    "        print(f\"depth: {depth}, hdim: {hdim}, forward_mem: {forward_mem:.4f}GB\")\n",
    "        if forward_mem > mem_limit:\n",
    "            if depth == 1:\n",
    "                hdim //= 2\n",
    "            else:\n",
    "                break\n",
    "        depth *= 2\n",
    "    scale = depth // 2\n",
    "    depth -= scale\n",
    "    while True:\n",
    "        model = MlpMixer(num_blocks=depth, embed_dim=hdim).cuda() \n",
    "        _, _, forward_mem, _, _ = get_stats(model, get_time=False)\n",
    "        scale //= 2\n",
    "        print(f\"depth: {depth}, hdim: {hdim}, forward_mem: {forward_mem:.4f}GB\")\n",
    "        if forward_mem > mem_limit: depth -= scale\n",
    "        else: depth += scale\n",
    "        if scale <= 1: break\n",
    "    return depth, hdim\n",
    "\n",
    "get_model_size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConvMixer(hdim, depth, kernel_size=9, patch_size=7, n_classes=1000)\n",
    "model = MlpMixer(num_blocks=depth, embed_dim=hdim).cuda() \n",
    "lr_schedule = lambda t: np.interp([t], [0, epochs*2//5, epochs*4//5, epochs], \n",
    "                                  [0, lr_max, lr_max/20.0, 0])[0]\n",
    "\n",
    "opt = optim.AdamW(model.parameters(), lr=lr_max, weight_decay=wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"batch_size: {batch_size}, hdim: {hdim}, depth: {depth}\")\n",
    "print(f\"Total params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Total params size in gb: {sum(p.element_size()*p.nelement() for p in model.parameters())/1024**3:.4f}GB\")\n",
    "preload_mem = 0.\n",
    "load_mem = 0.\n",
    "forward_mem = 0.\n",
    "transfered = 0\n",
    "step_time = []\n",
    "record_mem = 3\n",
    "record_time = list(range(4, 4+100))\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc, n = 0, 0, 0\n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "        if i in record_time: start_step = time.time()\n",
    "        if i == record_mem: preload_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "        model.train()\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        if i == record_mem:\n",
    "            load_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "            transfered += X.element_size() * X.nelement()\n",
    "            transfered += y.element_size() * y.nelement()\n",
    "\n",
    "        lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
    "        opt.param_groups[0].update(lr=lr)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        if i == record_mem:\n",
    "            forward_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "            transfered += loss.element_size() * loss.nelement()\n",
    "\n",
    "        loss.backward()\n",
    "        if clip_norm:\n",
    "            # scaler.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # scaler.step(opt)\n",
    "        # scaler.update()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss += loss.item() * y.size(0)\n",
    "        train_acc += (output.max(1)[1] == y).sum().item()\n",
    "        n += y.size(0)\n",
    "        # print(f\"step {i} of {len(trainloader)}\")\n",
    "        if i in record_time: step_time.append(time.time() - start_step)\n",
    "        if i == record_time[-1]: print(f'avg step time: {np.mean(step_time):.4f} +- {np.std(step_time)}s')\n",
    "\n",
    "        if i == record_mem:\n",
    "            print(f'preload_mem: {preload_mem:.4f}GB, load_mem: {load_mem:.4f}GB, forward_mem: {forward_mem:.4f}GB, transfered: {transfered/1024**2:.4f}MB')\n",
    "        \n",
    "    model.eval()\n",
    "    test_acc, m = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(X)\n",
    "            test_acc += (output.max(1)[1] == y).sum().item()\n",
    "            m += y.size(0)\n",
    "\n",
    "    print(f'[ConvMixer] Epoch: {epoch} | Train Acc: {train_acc/n:.4f}, Test Acc: {test_acc/m:.4f}, Time: {time.time() - start:.1f}, lr: {lr:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "# Measure the latency to move data from CPU to GPU, and GPU to CPU\n",
    "print(\"Measuring data transfer latency...\")\n",
    "latency = []\n",
    "for i in range(5,21):\n",
    "    data_amt = 1 << i\n",
    "    data = torch.randn(data_amt)\n",
    "    print(f\"Data amount: {data_amt} = {data_amt*data.element_size()/1024**3:.4f}GB = 2^{i}\")\n",
    "    cudata = data.cuda()\n",
    "    baseline = np.array(timeit.repeat(lambda: cudata.mean().cpu().numpy(), number=10000, repeat=7))\n",
    "    real = np.array(timeit.repeat(lambda: data.cuda().mean().cpu().numpy(), number=10000, repeat=7))\n",
    "    latency.append((real-baseline)/(data_amt * data.element_size()*10000))\n",
    "    print(f\"Latency: {np.mean(latency[-1]):.4e} ± {np.std(latency[-1]):.4e}s\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nplat = np.array(latency) * 1e9 \n",
    "#plot mean latency and std error bars\n",
    "# x = np.float32(2)**np.arange(5,21)\n",
    "x = np.arange(5,21)\n",
    "plt.plot(x, nplat.mean(1), label=\"mean\")\n",
    "plt.fill_between(x, nplat.mean(1)-nplat.std(1), nplat.mean(1)+nplat.std(1), alpha=0.5, label=\"std\")\n",
    "plt.xlabel(\"Data amount (2^i)\")\n",
    "plt.ylabel(\"Latency (ns / byte)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e3522f8c0d66f11a66b445b95395b0fa8bbeadf7a1b18599864fbc55528010c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
