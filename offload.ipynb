{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import ConvMixer, MlpMixer\n",
    "from torchvision.datasets import CIFAR10, ImageFolder\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.empty_cache())\n",
    "print(torch.cuda.memory_summary(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "hdim=1536\n",
    "depth=24\n",
    "\n",
    "epochs=1\n",
    "\n",
    "scale=0.75\n",
    "reprob=0.25\n",
    "ra_m=8\n",
    "ra_n=1\n",
    "jitter=0.1\n",
    "psize=2\n",
    "conv_ks=5\n",
    "wd=0.01\n",
    "clip_norm=True\n",
    "lr_max=0.01\n",
    "workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if not Path('data/tiny-imagenet-200').exists():\n",
    "    os.system('wget http://cs231n.stanford.edu/tiny-imagenet-200.zip -P data')\n",
    "    os.system('unzip -qq data/tiny-imagenet-200.zip -d data')\n",
    "\n",
    "DATA_DIR = 'data/tiny-imagenet-200' # Original images come in shapes of [3,64,64]\n",
    "\n",
    "# Define training and validation data paths\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VALID_DIR = os.path.join(DATA_DIR, 'val')\n",
    "\n",
    "traindata = ImageFolder(TRAIN_DIR, transform=T.Compose([\n",
    "    T.RandomResizedCrop(64, scale=(scale, 1.0)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "]))\n",
    "\n",
    "valdata = ImageFolder(VALID_DIR, transform=T.Compose([\n",
    "    T.Resize(64),\n",
    "    T.CenterCrop(64),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "]))\n",
    "\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "valloader = DataLoader(valdata, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "print(len(traindata))\n",
    "print(len(valdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "# cifar10_std = (0.2471, 0.2435, 0.2616)\n",
    "# train_transform = T.Compose([\n",
    "#     T.RandomResizedCrop(32, scale=(scale, 1.0), ratio=(1.0, 1.0)),\n",
    "#     T.RandomHorizontalFlip(p=0.5),\n",
    "#     T.RandAugment(num_ops=ra_n, magnitude=ra_m),\n",
    "#     T.ColorJitter(jitter, jitter, jitter),\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(cifar10_mean, cifar10_std),\n",
    "#     T.RandomErasing(p=reprob)\n",
    "# ])\n",
    "\n",
    "# test_transform = T.Compose([\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(cifar10_mean, cifar10_std)\n",
    "# ])\n",
    "# traindata = CIFAR10(root=\"data\", train=True, download=True, transform=train_transform)\n",
    "# testdata = CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "# trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "# testloader = DataLoader(testdata, batch_size=batch_size, shuffle=False, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConvMixer(hdim, depth, kernel_size=9, patch_size=7, n_classes=1000)\n",
    "model = MlpMixer(num_blocks=depth, embed_dim=hdim)\n",
    "model = model.cuda()\n",
    "lr_schedule = lambda t: np.interp([t], [0, epochs*2//5, epochs*4//5, epochs], \n",
    "                                  [0, lr_max, lr_max/20.0, 0])[0]\n",
    "\n",
    "opt = optim.AdamW(model.parameters(), lr=lr_max, weight_decay=wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"batch_size: {batch_size}, hdim: {hdim}, depth: {depth}\")\n",
    "print(f\"Total params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Total params size in gb: {sum(p.element_size()*p.nelement() for p in model.parameters())/1024**3:.4f}GB\")\n",
    "preload_mem = 0.\n",
    "load_mem = 0.\n",
    "forward_mem = 0.\n",
    "transfered = 0\n",
    "step_time = []\n",
    "record_mem = 3\n",
    "record_time = list(range(4, 4+100))\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc, n = 0, 0, 0\n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "        if i in record_time: start_step = time.time()\n",
    "        if i == record_mem: preload_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "        model.train()\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        if i == record_mem:\n",
    "            load_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "            transfered += X.element_size() * X.nelement()\n",
    "            transfered += y.element_size() * y.nelement()\n",
    "\n",
    "        lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
    "        opt.param_groups[0].update(lr=lr)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        if i == record_mem:\n",
    "            forward_mem = torch.cuda.memory_allocated(0)/1024**3\n",
    "            transfered += loss.element_size() * loss.nelement()\n",
    "\n",
    "        loss.backward()\n",
    "        if clip_norm:\n",
    "            # scaler.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # scaler.step(opt)\n",
    "        # scaler.update()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss += loss.item() * y.size(0)\n",
    "        train_acc += (output.max(1)[1] == y).sum().item()\n",
    "        n += y.size(0)\n",
    "        # print(f\"step {i} of {len(trainloader)}\")\n",
    "        if i in record_time: step_time.append(time.time() - start_step)\n",
    "        if i == record_time[-1]: print(f'avg step time: {np.mean(step_time):.4f} +- {np.std(step_time)}s')\n",
    "\n",
    "        if i == record_mem:\n",
    "            print(f'preload_mem: {preload_mem:.4f}GB, load_mem: {load_mem:.4f}GB, forward_mem: {forward_mem:.4f}GB, transfered: {transfered/1024**2:.4f}MB')\n",
    "        \n",
    "    model.eval()\n",
    "    test_acc, m = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(X)\n",
    "            test_acc += (output.max(1)[1] == y).sum().item()\n",
    "            m += y.size(0)\n",
    "\n",
    "    print(f'[ConvMixer] Epoch: {epoch} | Train Acc: {train_acc/n:.4f}, Test Acc: {test_acc/m:.4f}, Time: {time.time() - start:.1f}, lr: {lr:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e3522f8c0d66f11a66b445b95395b0fa8bbeadf7a1b18599864fbc55528010c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
